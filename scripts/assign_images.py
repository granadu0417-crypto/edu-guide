#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ë¯¸ì§€ ìë™ í• ë‹¹ ìŠ¤í¬ë¦½íŠ¸
Pexelsì™€ Unsplash APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì½˜í…ì¸ ì— ê³ ìœ í•œ ì´ë¯¸ì§€ í• ë‹¹
"""

import os
import re
import time
import random
import requests
from pathlib import Path

# API í‚¤
PEXELS_API_KEY = "1ZNOIZ70f0oMswRVoLVRWHeqioIxxRQr3CEAH4ZHhOr9E0q9rAEXBsJA"
UNSPLASH_ACCESS_KEY = "mARHwUbfiB7nMDACQgbKAKV0Guy_cmWAtsumV2htpJ4"

# ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ë§¤í•‘
CATEGORY_KEYWORDS = {
    'elementary': ['elementary student studying', 'child learning', 'primary school education', 'young student homework'],
    'middle': ['middle school student', 'teenager studying', 'junior high education', 'teen homework'],
    'high': ['high school student', 'teenager books', 'university entrance exam', 'advanced studying'],
    'subjects': {
        'korean': ['korean language book', 'reading comprehension', 'writing student', 'literature study'],
        'english': ['english learning', 'vocabulary book', 'foreign language student', 'english textbook'],
        'math': ['mathematics student', 'math problem solving', 'geometry study', 'calculator notebook'],
        'science': ['science experiment', 'laboratory student', 'microscope learning', 'chemistry education'],
        'social': ['geography student', 'history textbook', 'social studies map', 'world globe education']
    },
    'exam': ['student taking test', 'exam preparation', 'study schedule', 'test review notes'],
    'tutoring': ['one on one tutoring', 'private teacher student', 'personalized learning', 'tutor teaching'],
    'local': ['seoul cityscape', 'korean city education', 'urban school district', 'neighborhood learning center'],
    'consultation': ['counseling session', 'education consultation', 'parent teacher meeting', 'academic advice']
}

def get_pexels_image(query, page=1):
    """Pexels APIë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
    url = "https://api.pexels.com/v1/search"
    headers = {"Authorization": PEXELS_API_KEY}
    params = {
        "query": query,
        "per_page": 15,
        "page": page,
        "orientation": "landscape"
    }

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data['photos']:
                photo = random.choice(data['photos'])
                return photo['src']['large2x']
    except Exception as e:
        print(f"âš ï¸  Pexels API ì˜¤ë¥˜: {e}")

    return None

def get_unsplash_image(query, page=1):
    """Unsplash APIë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
    url = "https://api.unsplash.com/search/photos"
    headers = {"Authorization": f"Client-ID {UNSPLASH_ACCESS_KEY}"}
    params = {
        "query": query,
        "per_page": 15,
        "page": page,
        "orientation": "landscape"
    }

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data['results']:
                photo = random.choice(data['results'])
                return f"{photo['urls']['regular']}&w=1200&q=80"
    except Exception as e:
        print(f"âš ï¸  Unsplash API ì˜¤ë¥˜: {e}")

    return None

def get_category_from_path(file_path):
    """íŒŒì¼ ê²½ë¡œì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
    parts = file_path.parts
    for part in parts:
        if part in CATEGORY_KEYWORDS:
            return part

    # subjects í•˜ìœ„ ì¹´í…Œê³ ë¦¬ í™•ì¸
    if 'subjects' in parts:
        for i, part in enumerate(parts):
            if part == 'subjects' and i + 1 < len(parts):
                subject = parts[i + 1]
                if subject in CATEGORY_KEYWORDS['subjects']:
                    return f'subjects.{subject}'

    return 'general'

def get_search_keywords(category):
    """ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œ ë°˜í™˜"""
    if '.' in category:
        main, sub = category.split('.')
        return CATEGORY_KEYWORDS.get(main, {}).get(sub, ['education student studying'])

    keywords = CATEGORY_KEYWORDS.get(category, ['korean education student studying'])
    return keywords

def extract_front_matter(content):
    """Front Matter ì¶”ì¶œ"""
    match = re.match(r'^---\n(.*?)\n---\n', content, re.DOTALL)
    if match:
        return match.group(1), match.end()
    return None, 0

def update_featured_image(content, new_image_url):
    """featured_image í•„ë“œ ì—…ë°ì´íŠ¸"""
    # Front Matter ì¶”ì¶œ
    front_matter, end_pos = extract_front_matter(content)
    if not front_matter:
        return content, False

    # featured_image í•„ë“œ í™•ì¸
    if 'featured_image:' in front_matter:
        # ê¸°ì¡´ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        old_match = re.search(r'featured_image:\s*"([^"]+)"', front_matter)
        if old_match:
            old_url = old_match.group(1)
            # ê°™ì€ URLì´ë©´ ë³€ê²½ ì•ˆ í•¨
            if old_url == new_image_url:
                return content, False

            # ìƒˆ ì´ë¯¸ì§€ë¡œ êµì²´
            new_front_matter = re.sub(
                r'featured_image:\s*"[^"]+"',
                f'featured_image: "{new_image_url}"',
                front_matter
            )
        else:
            return content, False
    else:
        # featured_image í•„ë“œ ì¶”ê°€
        new_front_matter = front_matter + f'\nfeatured_image: "{new_image_url}"'

    # ì „ì²´ ì½˜í…ì¸  ì¬êµ¬ì„±
    new_content = f"---\n{new_front_matter}\n---\n" + content[end_pos:]
    return new_content, True

def process_markdown_file(file_path, used_images):
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì²˜ë¦¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ì¹´í…Œê³ ë¦¬ í™•ì¸
        category = get_category_from_path(file_path)
        keywords = get_search_keywords(category)

        # ëœë¤ í‚¤ì›Œë“œ ì„ íƒ
        query = random.choice(keywords)

        # API ì„ íƒ (ë²ˆê°ˆì•„ê°€ë©° ì‚¬ìš©)
        use_pexels = random.choice([True, False])

        new_image = None
        max_attempts = 5

        for attempt in range(max_attempts):
            if use_pexels:
                new_image = get_pexels_image(query, page=attempt+1)
            else:
                new_image = get_unsplash_image(query, page=attempt+1)

            # ì¤‘ë³µ í™•ì¸
            if new_image and new_image not in used_images:
                break

            # API ì „í™˜
            use_pexels = not use_pexels
            time.sleep(0.5)  # Rate limit ë°©ì§€

        if not new_image:
            print(f"âš ï¸  {file_path.name}: ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return False

        # ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
        new_content, updated = update_featured_image(content, new_image)

        if updated:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)

            used_images.add(new_image)
            source = "Pexels" if use_pexels else "Unsplash"
            print(f"âœ… {file_path.name}: {source} ì´ë¯¸ì§€ í• ë‹¹")
            return True
        else:
            return False

    except Exception as e:
        print(f"âŒ {file_path.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    content_dir = Path('content')

    if not content_dir.exists():
        print("âŒ content ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì°¾ê¸°
    md_files = list(content_dir.rglob('*.md'))

    print(f"ğŸ“ ì´ {len(md_files)}ê°œ íŒŒì¼ì— ì´ë¯¸ì§€ í• ë‹¹ ì‹œì‘...\n")

    used_images = set()
    processed_files = 0

    for i, md_file in enumerate(md_files, 1):
        print(f"[{i}/{len(md_files)}] ì²˜ë¦¬ ì¤‘...", end=" ")

        if process_markdown_file(md_file, used_images):
            processed_files += 1

        # Rate limit ë°©ì§€ (API í˜¸ì¶œ ì œí•œ)
        if i % 20 == 0:
            print("\nâ¸ï¸  20ê°œ ì²˜ë¦¬ë§ˆë‹¤ 3ì´ˆ ëŒ€ê¸° (API Rate Limit ë°©ì§€)...")
            time.sleep(3)

    print(f"\n{'='*60}")
    print(f"âœ… ì‘ì—… ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ë¯¸ì§€ í• ë‹¹ ì™„ë£Œ: {processed_files}ê°œ íŒŒì¼")
    print(f"ğŸ–¼ï¸  ì‚¬ìš©ëœ ê³ ìœ  ì´ë¯¸ì§€: {len(used_images)}ê°œ")
    print(f"{'='*60}")

if __name__ == '__main__':
    main()
