#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì „ì²´ ì‚¬ì´íŠ¸ ì¤‘ë³µ description ì œê±° ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  í´ë”ì˜ ì¤‘ë³µì„ íŒŒì¼ëª…ê³¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í™”
"""

from pathlib import Path
import re
from collections import defaultdict
import hashlib
import os

def get_file_number(file_path):
    """íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
    # elem-b10-1.md â†’ 10, 1
    # consultation-guide-23.md â†’ 23
    numbers = re.findall(r'\d+', file_path.stem)
    if numbers:
        return int(''.join(numbers))
    return hash(file_path.stem) % 1000

def generate_unique_suffix(file_path, content):
    """íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ê³ ìœ í•œ ì ‘ë¯¸ì‚¬ ìƒì„±"""
    # íŒŒì¼ ê²½ë¡œë¥¼ ì•ˆì •ì ì¸ hashë¡œ ë³€í™˜ (md5)
    path_str = str(file_path).encode('utf-8')
    path_hash = int(hashlib.md5(path_str).hexdigest(), 16)

    # 20ê°€ì§€ ë‹¤ì–‘í•œ ì ‘ë¯¸ì‚¬
    suffixes = [
        " ì „ë¬¸ê°€ì˜ ì„¸ì‹¬í•œ ê°€ì´ë“œë¡œ ì‹œì‘í•˜ì„¸ìš”.",
        " ê²€ì¦ëœ ë°©ë²•ìœ¼ë¡œ í™•ì‹¤í•œ ì„±ê³¼ë¥¼ ë§Œë“œì„¸ìš”.",
        " ë‹¨ê³„ë³„ ì‹¤ì²œ ì „ëµìœ¼ë¡œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì„¸ìš”.",
        " ë§ì¶¤í˜• ì†”ë£¨ì…˜ìœ¼ë¡œ ë¹ ë¥¸ í–¥ìƒì„ ê²½í—˜í•˜ì„¸ìš”.",
        " ì²´ê³„ì ì¸ ì ‘ê·¼ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
        " ì‹¤ì „ ë…¸í•˜ìš°ë¡œ ìì‹ ê°ì„ í‚¤ìš°ì„¸ìš”.",
        " íš¨ê³¼ì ì¸ ë°©ë²•ìœ¼ë¡œ ì‹¤ë ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
        " í•µì‹¬ ì „ëµìœ¼ë¡œ ì„±ê³µì˜ ê¸¸ì„ ì—´ì–´ê°€ì„¸ìš”.",
        " ì…ì¦ëœ ì‹œìŠ¤í…œìœ¼ë¡œ ëª©í‘œì— ë„ë‹¬í•˜ì„¸ìš”.",
        " ì „ëµì  ì ‘ê·¼ìœ¼ë¡œ ê²½ìŸë ¥ì„ ê°•í™”í•˜ì„¸ìš”.",
        " ì‹¤ìš©ì ì¸ íŒìœ¼ë¡œ ë¹ ë¥´ê²Œ ê°œì„ í•˜ì„¸ìš”.",
        " ì²´ê³„ì ì¸ í•™ìŠµë²•ìœ¼ë¡œ ì„±ì ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
        " íš¨ìœ¨ì ì¸ ì „ëµìœ¼ë¡œ ì‹œê°„ì„ ì ˆì•½í•˜ì„¸ìš”.",
        " ê²€ì¦ëœ ë…¸í•˜ìš°ë¡œ ì‹¤ë ¥ì„ í‚¤ìš°ì„¸ìš”.",
        " ë‹¨ê³„ë³„ ê°€ì´ë“œë¡œ í™•ì‹¤í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
        " ë§ì¶¤í˜• ì „ëµìœ¼ë¡œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì„¸ìš”.",
        " ì‹¤ì „ ì¤‘ì‹¬ ë°©ë²•ìœ¼ë¡œ ì„±ê³¼ë¥¼ ë§Œë“œì„¸ìš”.",
        " ì²´ê³„ì ì¸ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
        " íš¨ê³¼ì ì¸ í•™ìŠµë²•ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì„¸ìš”.",
        " ì „ë¬¸ê°€ì˜ ë…¸í•˜ìš°ë¡œ ìì‹ ê°ì„ í‚¤ìš°ì„¸ìš”.",
    ]

    # MD5 hashë¡œ suffix ì„ íƒ (ì•ˆì •ì ì´ê³  ê³ ìœ )
    return suffixes[path_hash % len(suffixes)]

def fix_description(file_path, force=False):
    """íŒŒì¼ì˜ descriptionì„ ê³ ìœ í•˜ê²Œ ìˆ˜ì •"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if not content.startswith('---'):
            return False

        parts = content.split('---', 2)
        if len(parts) < 3:
            return False

        front_matter = parts[1]
        body = parts[2]

        # Description ì¶”ì¶œ
        desc_match = re.search(r'^description:\s*(.+?)(?=\n[a-z_]+:|$)', front_matter, re.MULTILINE | re.DOTALL)
        if not desc_match:
            return False

        old_description = desc_match.group(1).strip()

        # force=Trueê°€ ì•„ë‹ˆë©´ ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì€ ê±´ë„ˆëœ€
        if not force:
            check_phrases = [
                "ì „ë¬¸ê°€ì˜ ì„¸ì‹¬í•œ", "ê²€ì¦ëœ ë°©ë²•ìœ¼ë¡œ", "ë‹¨ê³„ë³„ ì‹¤ì²œ",
                "ë§ì¶¤í˜• ì†”ë£¨ì…˜", "ì²´ê³„ì ì¸ ì ‘ê·¼", "ì‹¤ì „ ë…¸í•˜ìš°",
                "íš¨ê³¼ì ì¸ ë°©ë²•", "í•µì‹¬ ì „ëµ", "ì…ì¦ëœ ì‹œìŠ¤í…œ",
                "ì „ëµì  ì ‘ê·¼", "ë¶„ì•¼ ì „ë¬¸ ê°€ì´ë“œ", "ì‹¤ìš©ì ì¸ íŒ",
                "ì²´ê³„ì ì¸ í•™ìŠµë²•", "íš¨ìœ¨ì ì¸ ì „ëµ", "ê²€ì¦ëœ ë…¸í•˜ìš°",
                "ë‹¨ê³„ë³„ ê°€ì´ë“œ", "ì‹¤ì „ ì¤‘ì‹¬", "ì „ë¬¸ê°€ì˜ ë…¸í•˜ìš°"
            ]

            if any(phrase in old_description for phrase in check_phrases):
                return False  # ì´ë¯¸ ì²˜ë¦¬ë¨

        # ê¸°ì¡´ ì ‘ë¯¸ì‚¬ ì œê±° (force=Trueì¼ ë•Œ)
        if force:
            # ê¸°ì¡´ ì ‘ë¯¸ì‚¬ íŒ¨í„´ë“¤ ì œê±°
            base_desc = old_description
            for phrase in [
                "ì „ë¬¸ê°€ì˜ ì„¸ì‹¬í•œ ê°€ì´ë“œë¡œ ì‹œì‘í•˜ì„¸ìš”.",
                "ê²€ì¦ëœ ë°©ë²•ìœ¼ë¡œ í™•ì‹¤í•œ ì„±ê³¼ë¥¼ ë§Œë“œì„¸ìš”.",
                "ë‹¨ê³„ë³„ ì‹¤ì²œ ì „ëµìœ¼ë¡œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì„¸ìš”.",
                "ë§ì¶¤í˜• ì†”ë£¨ì…˜ìœ¼ë¡œ ë¹ ë¥¸ í–¥ìƒì„ ê²½í—˜í•˜ì„¸ìš”.",
                "ì²´ê³„ì ì¸ ì ‘ê·¼ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
                "ì‹¤ì „ ë…¸í•˜ìš°ë¡œ ìì‹ ê°ì„ í‚¤ìš°ì„¸ìš”.",
                "íš¨ê³¼ì ì¸ ë°©ë²•ìœ¼ë¡œ ì‹¤ë ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
                "í•µì‹¬ ì „ëµìœ¼ë¡œ ì„±ê³µì˜ ê¸¸ì„ ì—´ì–´ê°€ì„¸ìš”.",
                "ì…ì¦ëœ ì‹œìŠ¤í…œìœ¼ë¡œ ëª©í‘œì— ë„ë‹¬í•˜ì„¸ìš”.",
                "ì „ëµì  ì ‘ê·¼ìœ¼ë¡œ ê²½ìŸë ¥ì„ ê°•í™”í•˜ì„¸ìš”.",
                "ì‹¤ìš©ì ì¸ íŒìœ¼ë¡œ ë¹ ë¥´ê²Œ ê°œì„ í•˜ì„¸ìš”.",
                "ì²´ê³„ì ì¸ í•™ìŠµë²•ìœ¼ë¡œ ì„±ì ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
                "íš¨ìœ¨ì ì¸ ì „ëµìœ¼ë¡œ ì‹œê°„ì„ ì ˆì•½í•˜ì„¸ìš”.",
                "ê²€ì¦ëœ ë…¸í•˜ìš°ë¡œ ì‹¤ë ¥ì„ í‚¤ìš°ì„¸ìš”.",
                "ë‹¨ê³„ë³„ ê°€ì´ë“œë¡œ í™•ì‹¤í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
                "ë§ì¶¤í˜• ì „ëµìœ¼ë¡œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì„¸ìš”.",
                "ì‹¤ì „ ì¤‘ì‹¬ ë°©ë²•ìœ¼ë¡œ ì„±ê³¼ë¥¼ ë§Œë“œì„¸ìš”.",
                "ì²´ê³„ì ì¸ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”.",
                "íš¨ê³¼ì ì¸ í•™ìŠµë²•ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì„¸ìš”.",
                "ì „ë¬¸ê°€ì˜ ë…¸í•˜ìš°ë¡œ ìì‹ ê°ì„ í‚¤ìš°ì„¸ìš”."
            ]:
                if phrase in base_desc:
                    base_desc = base_desc.replace(phrase, "").strip()

            # "XX ë¶„ì•¼ ì „ë¬¸ ê°€ì´ë“œì…ë‹ˆë‹¤." íŒ¨í„´ ì œê±°
            base_desc = re.sub(r'\s+[^.]+\s+ë¶„ì•¼ ì „ë¬¸ ê°€ì´ë“œì…ë‹ˆë‹¤\.\s*', '', base_desc).strip()
            old_description = base_desc

        # ê³ ìœ  ì ‘ë¯¸ì‚¬ ìƒì„±
        unique_suffix = generate_unique_suffix(file_path, content)

        # ìƒˆ description ìƒì„± (ê¸°ì¡´ + ì ‘ë¯¸ì‚¬)
        # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ ìë¥´ê¸°
        max_base_length = 140
        if len(old_description) > max_base_length:
            old_description = old_description[:max_base_length].rsplit(' ', 1)[0] + '...'

        new_description = old_description + unique_suffix

        # Description êµì²´
        desc_pattern = r'^description:.*?(?=\n[a-z_]+:|\ntags:)'
        new_desc = f'description: {new_description}'

        new_front_matter = re.sub(desc_pattern, new_desc, front_matter, flags=re.MULTILINE | re.DOTALL)

        # íŒŒì¼ ì €ì¥
        new_content = f"---{new_front_matter}---{body}"

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return True

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {file_path.name} - {e}")
        return False

def find_duplicates(content_dir):
    """ì¤‘ë³µ description ì°¾ê¸°"""
    descriptions = defaultdict(list)

    for md_file in content_dir.glob('**/*.md'):
        if md_file.name.startswith('_'):
            continue

        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()

            desc_match = re.search(r'^description:\s*(.+?)(?=\n[a-z_]+:|$)', content, re.MULTILINE | re.DOTALL)
            if desc_match:
                desc = desc_match.group(1).strip()
                descriptions[desc].append(str(md_file.relative_to(content_dir)))
        except:
            continue

    # ì¤‘ë³µë§Œ ë°˜í™˜
    duplicates = {desc: files for desc, files in descriptions.items() if len(files) > 1}
    return duplicates

def main():
    content_dir = Path('content')

    print("ğŸ” ì „ì²´ ì‚¬ì´íŠ¸ ì¤‘ë³µ description ë¶„ì„...\n")

    # ì¤‘ë³µ ë°œê²¬
    duplicates = find_duplicates(content_dir)
    print(f"ì¤‘ë³µ ë°œê²¬: {len(duplicates)}ê°œ descriptionì´ {sum(len(files) for files in duplicates.values())}ê°œ íŒŒì¼ì—ì„œ ì¤‘ë³µ\n")

    if not duplicates:
        print("âœ… ì¤‘ë³µ ì—†ìŒ!")
        return

    print("ğŸ”§ ì¤‘ë³µ description ê³ ìœ í™” ì‹œì‘...\n")

    # ì¤‘ë³µëœ íŒŒì¼ë“¤ë§Œ ì²˜ë¦¬ (force=Trueë¡œ ê°•ì œ ì¬ì²˜ë¦¬)
    fixed_count = 0
    files_to_fix = set()

    for desc, file_list in duplicates.items():
        for file_path_str in file_list:
            files_to_fix.add(content_dir / file_path_str)

    for file_path in sorted(files_to_fix):
        if fix_description(file_path, force=True):  # force=True ì¶”ê°€
            fixed_count += 1
            if fixed_count <= 10:
                rel_path = file_path.relative_to(content_dir)
                print(f"âœ… [{fixed_count}] {rel_path}")

    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š Description ê³ ìœ í™” ì™„ë£Œ")
    print(f"{'=' * 80}")
    print(f"ìˆ˜ì •ëœ íŒŒì¼: {fixed_count}ê°œ")

    # ê²°ê³¼ ì¬í™•ì¸
    print(f"\nğŸ” ìµœì¢… ê²€ì¦ ì¤‘...")
    final_duplicates = find_duplicates(content_dir)
    print(f"ë‚¨ì€ ì¤‘ë³µ: {len(final_duplicates)}ê°œ description")
    print(f"{'=' * 80}")

if __name__ == '__main__':
    main()
