#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tutoring í´ë” SEO ìƒíƒœ ë¶„ì„
"""

from pathlib import Path
import re

def analyze_file(file_path):
    """íŒŒì¼ SEO ìƒíƒœ ë¶„ì„"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if not content.startswith('---'):
            return None

        parts = content.split('---', 2)
        if len(parts) < 3:
            return None

        front_matter = parts[1]
        body = parts[2]

        # Description ê¸¸ì´
        desc_match = re.search(r'^description:\s*["\']?(.+?)["\']?(?=\n[a-z_]+:|$)', front_matter, re.MULTILINE | re.DOTALL)
        desc_length = len(desc_match.group(1).strip()) if desc_match else 0

        # Tags ê°œìˆ˜
        tags_match = re.search(r'^tags:\s*(\[.+?\])', front_matter, re.MULTILINE | re.DOTALL)
        if tags_match:
            tags_str = tags_match.group(1)
            tags_count = len(re.findall(r'"[^"]+"|\'[^\']+\'|\w+', tags_str))
        else:
            tags_count = 0

        # Featured Image ì¡´ì¬
        has_image = bool(re.search(r'^featured_image:', front_matter, re.MULTILINE))

        # ì½˜í…ì¸  ë‹¨ì–´ ìˆ˜
        words = len(body.split())

        # Reading time
        has_reading_time = bool(re.search(r'^reading_time:', front_matter, re.MULTILINE))

        return {
            'path': str(file_path.relative_to(Path('content'))),
            'desc_length': desc_length,
            'tags_count': tags_count,
            'has_image': has_image,
            'words': words,
            'has_reading_time': has_reading_time
        }
    except:
        return None

def main():
    content_dir = Path('content/tutoring')

    print("ğŸ” Tutoring í´ë” SEO ìƒíƒœ ë¶„ì„\n")

    files_data = []
    for md_file in content_dir.rglob('*.md'):
        data = analyze_file(md_file)
        if data:
            files_data.append(data)

    if not files_data:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ì´ íŒŒì¼ ìˆ˜: {len(files_data)}ê°œ\n")

    # í†µê³„
    desc_150_plus = sum(1 for f in files_data if f['desc_length'] >= 150)
    desc_under_150 = len(files_data) - desc_150_plus

    tags_8_plus = sum(1 for f in files_data if f['tags_count'] >= 8)
    tags_under_8 = len(files_data) - tags_8_plus

    has_image = sum(1 for f in files_data if f['has_image'])
    no_image = len(files_data) - has_image

    words_500_plus = sum(1 for f in files_data if f['words'] >= 500)
    words_under_500 = len(files_data) - words_500_plus

    has_reading = sum(1 for f in files_data if f['has_reading_time'])
    no_reading = len(files_data) - has_reading

    # í‰ê· 
    avg_desc = sum(f['desc_length'] for f in files_data) / len(files_data)
    avg_tags = sum(f['tags_count'] for f in files_data) / len(files_data)
    avg_words = sum(f['words'] for f in files_data) / len(files_data)

    print("=" * 80)
    print("ğŸ“Š SEO í˜„í™©")
    print("=" * 80)
    print(f"âœ… Description 150ì ì´ìƒ: {desc_150_plus}ê°œ ({desc_150_plus/len(files_data)*100:.1f}%)")
    print(f"âš ï¸  Description 150ì ë¯¸ë§Œ: {desc_under_150}ê°œ")
    print()
    print(f"âœ… Tags 8ê°œ ì´ìƒ: {tags_8_plus}ê°œ ({tags_8_plus/len(files_data)*100:.1f}%)")
    print(f"âš ï¸  Tags 8ê°œ ë¯¸ë§Œ: {tags_under_8}ê°œ")
    print()
    print(f"âœ… Featured Image ìˆìŒ: {has_image}ê°œ ({has_image/len(files_data)*100:.1f}%)")
    print(f"âš ï¸  Featured Image ì—†ìŒ: {no_image}ê°œ")
    print()
    print(f"âœ… ì½˜í…ì¸  500ë‹¨ì–´ ì´ìƒ: {words_500_plus}ê°œ ({words_500_plus/len(files_data)*100:.1f}%)")
    print(f"âš ï¸  ì½˜í…ì¸  500ë‹¨ì–´ ë¯¸ë§Œ: {words_under_500}ê°œ")
    print()
    print(f"âœ… Reading Time ìˆìŒ: {has_reading}ê°œ ({has_reading/len(files_data)*100:.1f}%)")
    print(f"âš ï¸  Reading Time ì—†ìŒ: {no_reading}ê°œ")
    print("=" * 80)
    print()
    print("ğŸ“ˆ í‰ê·  ìˆ˜ì¹˜")
    print(f"Description í‰ê· : {avg_desc:.1f}ì")
    print(f"Tags í‰ê· : {avg_tags:.1f}ê°œ")
    print(f"ì½˜í…ì¸  í‰ê· : {avg_words:.0f}ë‹¨ì–´")
    print()

    # ê°œì„  í•„ìš” íŒŒì¼ ëª©ë¡
    needs_improvement = []
    for f in files_data:
        issues = []
        if f['desc_length'] < 150:
            issues.append('desc')
        if f['tags_count'] < 8:
            issues.append('tags')
        if not f['has_image']:
            issues.append('image')
        if f['words'] < 500:
            issues.append('words')
        if not f['has_reading_time']:
            issues.append('reading')

        if issues:
            needs_improvement.append((f['path'], issues))

    if needs_improvement:
        print("âš ï¸  ê°œì„  í•„ìš” íŒŒì¼:", len(needs_improvement), "ê°œ")
        print("=" * 80)
        print()
        for path, issues in needs_improvement[:10]:
            print(f"{path}")
            print(f"  ë¬¸ì œ: {', '.join(issues)}")
            print()

        if len(needs_improvement) > 10:
            print(f"... ì™¸ {len(needs_improvement) - 10}ê°œ ë”")

    print(f"\nğŸ’¡ ì´ {len(needs_improvement)}ê°œ íŒŒì¼ì´ ê°œì„  í•„ìš”")
    print("=" * 80)

if __name__ == '__main__':
    main()
